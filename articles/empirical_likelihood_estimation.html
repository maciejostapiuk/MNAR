<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Empirical Likelihood Method â€¢ MNAR</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.4.2/css/all.min.css" rel="stylesheet">
<link href="../deps/font-awesome-6.4.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Empirical Likelihood Method">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">MNAR</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.0.0.9000</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="active nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-articles" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Articles</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-articles">
<li><a class="dropdown-item" href="../articles/calibration_weighting.html">Calibration weighting</a></li>
    <li><a class="dropdown-item" href="../articles/empirical_likelihood_estimation.html">Empirical Likelihood Method</a></li>
    <li><a class="dropdown-item" href="../articles/theory.html">Theory for missing not at random non-response correction</a></li>
  </ul>
</li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json">
</form></li>
      </ul>
</div>


  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">

      <h1>Empirical Likelihood Method</h1>
                        <h4 data-toc-skip class="author">Maciej Ostapiuk
and Maciej BerÄ™sewicz</h4>
            
      

      <div class="d-none name"><code>empirical_likelihood_estimation.Rmd</code></div>
    </div>

    
    
<div class="section level2">
<h2 id="empirical-likelihood-method">Empirical Likelihood Method<a class="anchor" aria-label="anchor" href="#empirical-likelihood-method"></a>
</h2>
<p>To consider the empirical likelihood under non-ignorable missing
data, one has to discuss the distribution function of multidimensional
random variable
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="true" form="prefix">(</mo><mi>ğ—</mi><mo>,</mo><mi>Y</mi><mo stretchy="true" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">(\boldsymbol{X},Y)</annotation></semantics></math>
which is determined by its distribution function
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>F</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">F(x,y)</annotation></semantics></math>.
There are no assumptions on
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>F</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">F(x,y)</annotation></semantics></math>
(except the fact that it has to fit CDF assumptions) but there is a
setting in <span class="citation">Kim and Shao (<a href="#ref-kim_statistical_2013">2013</a>)</span>, that
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>ğ”¼</mo><mo stretchy="false" form="prefix">{</mo><mi>U</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>ğ›‰</mi><mn>0</mn></msub><mo>;</mo><mi>X</mi><mo>,</mo><mi>Y</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo stretchy="false" form="postfix">}</mo><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">\begin{equation}\label{eq: setting on (X,Y)}
\mathop{\mathrm{\mathbb{E}}}\{U(\boldsymbol{\theta}_0; X,Y)\} = 0 
\end{equation}</annotation></semantics></math> which is a
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>m</mi><annotation encoding="application/x-tex">m</annotation></semantics></math>-dimensional,
linearly independent vector,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>U</mi><mrow><mo stretchy="true" form="prefix">(</mo><mo>â‹…</mo><mo stretchy="true" form="postfix">)</mo></mrow><mo>âˆˆ</mo><msup><mi>ğ’</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">U(\cdot) \in \mathcal{C}^2</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>ğ›‰</mi><mn>0</mn></msub><mo>âˆˆ</mo><mi>Î©</mi><mo>âŠ†</mo><msup><mi>â„</mi><mi>p</mi></msup></mrow><annotation encoding="application/x-tex">\boldsymbol{\theta}_0 \in \Omega \subseteq \mathbb{R}^p</annotation></semantics></math>.
if
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi><mo>=</mo><mi>p</mi></mrow><annotation encoding="application/x-tex">m = p</annotation></semantics></math>,
then a consistent estimator of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>ğ›‰</mi><mn>0</mn></msub><annotation encoding="application/x-tex">\boldsymbol{\theta}_0</annotation></semantics></math>
is a solution of:
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><munderover><mo>âˆ‘</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mi>U</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>ğ›‰</mi><mo>,</mo><msub><mi>ğ±</mi><mi>i</mi></msub><mo>,</mo><mi>y</mi><mo stretchy="true" form="postfix">)</mo></mrow><mi>.</mi></mrow><annotation encoding="application/x-tex">\begin{equation}\label{eq: consistent estimator of btheta under m = p}
\sum_{i=1}^{n} U(\boldsymbol{\theta}, \boldsymbol{x}_i, y).
\end{equation}</annotation></semantics></math> When
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi><mo>&gt;</mo><mi>p</mi></mrow><annotation encoding="application/x-tex">m &gt; p</annotation></semantics></math>
the model is called , thus one has to adjust the methodology which
results in different optimization problem, since might not provide
solution at all. This adjustment is also proposed in <span class="citation">Kim and Shao (<a href="#ref-kim_statistical_2013">2013</a>)</span> and the EL approach is
concentrated around finding a solution
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ›‰</mi><annotation encoding="application/x-tex">\boldsymbol{\theta}</annotation></semantics></math>
that maximizes the empirical likelihood function of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ›‰</mi><annotation encoding="application/x-tex">\boldsymbol{\theta}</annotation></semantics></math>:
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>ğ›‰</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><msub><mo>argâ€†max</mo><mi>ğ›‰</mi></msub><mrow><mo stretchy="true" form="prefix">{</mo><munderover><mo>âˆ</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><msub><mi>p</mi><mi>i</mi></msub><mo>:</mo><msub><mi>p</mi><mi>i</mi></msub><mo>&gt;</mo><mn>0</mn><mo>,</mo><munderover><mo>âˆ‘</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><msub><mi>p</mi><mi>i</mi></msub><mo>âˆ§</mo><munderover><mo>âˆ‘</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><msub><mi>p</mi><mi>i</mi></msub><mi>U</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>ğ›‰</mi><mo>;</mo><msub><mi>ğ±</mi><mi>i</mi></msub><mo>,</mo><msub><mi>y</mi><mi>i</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mn>0</mn><mo stretchy="true" form="postfix">}</mo></mrow><mi>.</mi></mrow><annotation encoding="application/x-tex">\begin{equation}\label{eq: EL solution for m&gt;p}
L(\boldsymbol{\theta}) = \mathop{\mathrm{arg\,max}}_{\boldsymbol{\theta}}\left\{\prod_{i=1}^n p_i: p_i&gt;0, \sum_{i=1}^np_i \wedge \sum_{i=1}^n p_i U(\boldsymbol{\theta}; \boldsymbol{x}_i, y_i) = 0\right\}.
\end{equation}</annotation></semantics></math> Using the Lagrange
multiplier method, lets denote
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mover><mi>p</mi><mo accent="true">Ì‚</mo></mover><mi>i</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>ğ›‰</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mfrac><mn>1</mn><mi>n</mi></mfrac><mfrac><mn>1</mn><mrow><mn>1</mn><mo>+</mo><msub><mover><mi>Î»</mi><mo accent="true">Ì‚</mo></mover><mi>ğ›‰</mi></msub><mi>â€²</mi><mi>U</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>Î¸</mi><mo>;</mo><msub><mi>ğ±</mi><mi>i</mi></msub><mo>,</mo><msub><mi>y</mi><mi>i</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow></mfrac><mi>.</mi></mrow><annotation encoding="application/x-tex">\begin{equation}
    \hat{p}_i(\boldsymbol{\theta})  =\frac{1}{n} \frac{1}{1+\hat{\lambda}_{\boldsymbol{\theta}}'U(\theta; \boldsymbol{x}_i, y_i)}.
\end{equation}</annotation></semantics></math> Thus, the MEL estimator
is being obtained by maximizing
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>l</mi><mi>e</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>ğ›‰</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><munderover><mo>âˆ‘</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mo>log</mo><mo stretchy="false" form="prefix">{</mo><msub><mover><mi>p</mi><mo accent="true">Ì‚</mo></mover><mi>i</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>ğ›‰</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo stretchy="false" form="postfix">}</mo><mi>.</mi></mrow><annotation encoding="application/x-tex">\begin{equation} \label{eq: empirical likelihood method estimator}
l_e(\boldsymbol{\theta}) = \sum_{i=1}^n\log\{\hat{p}_i(\boldsymbol{\theta})\}.
\end{equation}</annotation></semantics></math> When dealing with any
missingness in data, (recall, that we do have
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>ğ±</mi><mi>i</mi></msub><annotation encoding="application/x-tex">\boldsymbol{x}_i</annotation></semantics></math>
for any individual and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>y</mi><mi>i</mi></msub><annotation encoding="application/x-tex">y_i</annotation></semantics></math>
is only observed for respondents) the scoring of propensity is applied
in such fashion:</p>
<ul>
<li>let
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>R</mi><annotation encoding="application/x-tex">R</annotation></semantics></math>
be a response indicator
(<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>R</mi><mi>i</mi></msub><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">R_i=1</annotation></semantics></math>
if
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>y</mi><mi>i</mi></msub><annotation encoding="application/x-tex">y_i</annotation></semantics></math>
is observed and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>R</mi><mi>i</mi></msub><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">R_i=0</annotation></semantics></math>
if
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>y</mi><mi>i</mi></msub><annotation encoding="application/x-tex">y_i</annotation></semantics></math>
is unobserved),</li>
<li>denote response propensity as
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Ï€</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>ğ±</mi><mo>;</mo><mi>Ï•</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mi>P</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>R</mi><mo>=</mo><mn>1</mn><mo stretchy="false" form="prefix">|</mo><mi>ğ±</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\pi(\boldsymbol{x};\phi) = P(R =1|\boldsymbol{x})</annotation></semantics></math>
(MNAR mechanism provides lack of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>y</mi><mi>i</mi></msub><annotation encoding="application/x-tex">y_i</annotation></semantics></math>
in conditioning),</li>
<li>let
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>Ï•</mi><mo>;</mo><mi>R</mi><mo>,</mo><mi>ğ±</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">S(\phi; R, \boldsymbol{x})</annotation></semantics></math>
be the score function of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Ï•</mi><annotation encoding="application/x-tex">\phi</annotation></semantics></math>
s.t.
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>ğ”¼</mo><mo stretchy="false" form="prefix">{</mo><mi>S</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>Ï•</mi><mo>;</mo><mi>R</mi><mo>,</mo><mi>ğ±</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo stretchy="false" form="postfix">}</mo><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">\mathop{\mathrm{\mathbb{E}}}\{S(\phi; R, \boldsymbol{x})\} = 0</annotation></semantics></math>
holds.</li>
</ul>
<p>Thus,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>ğ”¼</mo><mo stretchy="false" form="prefix">{</mo><mi>S</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>Ï•</mi><mo>;</mo><mi>R</mi><mo>,</mo><mi>ğ±</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo stretchy="false" form="postfix">}</mo><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">\mathop{\mathrm{\mathbb{E}}}\{S(\phi; R, \boldsymbol{x})\} = 0</annotation></semantics></math>
is one of the moment conditions, along with second one of form:
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>ğ”¼</mo><mrow><mo stretchy="true" form="prefix">{</mo><mfrac><mi>R</mi><mrow><mi>Ï€</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>ğ—</mi><mo>;</mo><mi>Ï•</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow></mfrac><mi>U</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>ğ›‰</mi><mo>,</mo><mi>ğ—</mi><mo>,</mo><mi>Y</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo stretchy="true" form="postfix">}</mo></mrow><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">\begin{equation}\label{eq: second moment condition for EL by PS}
\mathop{\mathrm{\mathbb{E}}}\left\{\frac{R}{\pi(\boldsymbol{X};\phi)}U(\boldsymbol{\theta},\boldsymbol{X}, Y)\right\} = 0
\end{equation}</annotation></semantics></math> Those two moment
conditions allows us to perform propensity-score-based MELE by
maximizing:
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>ğ›‰</mi><mo>,</mo><mi>Ï•</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mo>argâ€†max</mo><mrow><mo stretchy="true" form="prefix">{</mo><munderover><mo>âˆ</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><msub><mi>p</mi><mi>i</mi></msub><mo>:</mo><mi>ğ©</mi><mo>âˆˆ</mo><mi>B</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>ğ›‰</mi><mo>,</mo><mi>Ï•</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo stretchy="true" form="postfix">}</mo></mrow><mo>,</mo></mrow><annotation encoding="application/x-tex">\begin{equation}\label{eq: MELE by PS}
L(\boldsymbol{\theta}, \phi) = \mathop{\mathrm{arg\,max}}\left\{\prod_{i=1}^n p_i: \boldsymbol{p}\in B(\boldsymbol{\theta}, \phi) \right\},
\end{equation}</annotation></semantics></math> where <span class="math display">$$\begin{equation}\label{eq: F(\boldsymbol{\theta},
\phi) definition}
B(\boldsymbol{\theta}, \phi) = \left\{\boldsymbol{p}: p_i&gt;0,
\sum_{i=1}^np_i, \sum_{i=1}^n p_i\frac{R_i}{\pi(\boldsymbol{x}_i;\phi)}
U(\boldsymbol{\theta}; \boldsymbol{x}_i, y_i) = 0\, \sum_{i=1}^n p_i
S(\phi; R_i, \boldsymbol{x}_i) = 0 \right\}.
\end{equation}$$</span></p>
</div>
<div class="section level2">
<h2 class="unnumbered" id="references">References<a class="anchor" aria-label="anchor" href="#references"></a>
</h2>
<div id="refs" class="references csl-bib-body hanging-indent" entry-spacing="0">
<div id="ref-kim_statistical_2013" class="csl-entry">
Kim, J. K., and J. Shao. 2013. <em>Statistical <span>Methods</span> for
<span>Handling</span> <span>Incomplete</span> <span>Data</span></em>.
Chapman &amp; <span>Hall</span> Book. Taylor &amp; Francis. <a href="https://books.google.pl/books?id=MY4AAAAAQBAJ" class="external-link">https://books.google.pl/books?id=MY4AAAAAQBAJ</a>.
</div>
</div>
</div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by Maciej Ostapiuk, Maciej BerÄ™sewicz.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.1.</p>
</div>

    </footer>
</div>





  </body>
</html>
